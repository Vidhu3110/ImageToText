# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JKdRJThsV-z8u1n_8MljaMTJpr9ikJXy
"""

# Commented out IPython magic to ensure Python compatibility.
!sudo apt install tesseract-ocr
!pip install pytesseract
import cv2
import numpy as np
import pytesseract
from pytesseract.pytesseract import Output
# %matplotlib inline
pytesseract.tesseract_cmd = r'C:\Users\vidhu\AppData\Local\Tesseract-OCR\tesseract.exe'

from matplotlib import pyplot as plt

img = cv2.imread('/content/1200px-Section_break_01_by_Pengo.jpg')
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
pytesseract
##############################################
##### Image to String   ######
##############################################

def get_grayscale(image):
    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

# noise removal
def remove_noise(image):
    return cv2.medianBlur(image,5)
 
#thresholding
def thresholding(image):
    return cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]

#dilation
def dilate(image):
    kernel = np.ones((5,5),np.uint8)
    return cv2.dilate(image, kernel, iterations = 1)
    
#erosion
def erode(image):
    kernel = np.ones((5,5),np.uint8)
    return cv2.erode(image, kernel, iterations = 1)

#opening - erosion followed by dilation
def opening(image):
    kernel = np.ones((5,5),np.uint8)
    return cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)

#canny edge detection
def canny(image):
    return cv2.Canny(image, 100, 200)

#skew correction
def deskew(image):
    coords = np.column_stack(np.where(image > 0))
    angle = cv2.minAreaRect(coords)[-1]
    if angle < -45:
        angle = -(90 + angle)
    else:
        angle = -angle
    (h, w) = image.shape[:2]
    center = (w // 2, h // 2)
    M = cv2.getRotationMatrix2D(center, angle, 1.0)
    rotated = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)
    return rotated

#template matching
def match_template(image, template):
    return cv2.matchTemplate(image, template, cv2.TM_CCOEFF_NORMED)


rem_noise = remove_noise(img)
gray = get_grayscale(rem_noise)
thresh = thresholding(gray)
open = opening(gray)
can = canny(gray)
ero = erode(gray)
print(pytesseract.image_to_string(img))

l = []

l.append(pytesseract.image_to_string(img))

hImg, wImg,_ = img.shape
conf = r'--oem 3 --psm 6 outputbase digits'
boxes = pytesseract.image_to_boxes(open,config=conf)
for b in boxes.splitlines():
    print(b)
    b = b.split(' ')
    print(b)
    x, y, w, h = int(b[1]), int(b[2]), int(b[3]), int(b[4])
    cv2.rectangle(gray, (x,hImg- y), (w,hImg- h), (50, 50, 255), 2)
    #cv2.putText(ero,b[0],(x,hImg- y+25),cv2.FONT_HERSHEY_SIMPLEX,1,(50,50,255),2)


boxes = pytesseract.image_to_data(img)
for a,b in enumerate(boxes.splitlines()):
        print(b)
        if a!=0:
            b = b.split()
            if len(b)==12:
                x,y,w,h = int(b[6]),int(b[7]),int(b[8]),int(b[9])
                #cv2.putText(ero,b[11],(x,y-5),cv2.FONT_HERSHEY_SIMPLEX,1,(50,50,255),2)
                cv2.rectangle(gray, (x,y), (x+w, y+h), (50, 50, 255), 2)
                hImg, wImg,_ = img.shape

plt.imshow(img)
plt.show()

pytesseract.image_to_string(img)

import numpy as np
import pandas as pd 
import os
import re
import itertools
import nltk
import seaborn as sns
from sklearn.linear_model import LogisticRegression
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
from nltk.stem import WordNetLemmatizer 
from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer
from sklearn.ensemble import RandomForestClassifier
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split
from textblob import TextBlob
from sklearn import svm
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import confusion_matrix, classification_report,accuracy_score,f1_score
from textblob import TextBlob
def text_processing(tweet):
    
    def form_sentence(tweet):
        tweet_blob = TextBlob(tweet)
        return ' '.join(tweet_blob.words)
    new_tweet = form_sentence(tweet)
    
    def no_user_alpha(tweet):
        tweet_list = [ele for ele in tweet.split() if ele != 'user']
        clean_tokens = [t for t in tweet_list if re.match(r'[^\W\d]*$', t)]
        clean_s = ' '.join(clean_tokens)
        clean_mess = [word for word in clean_s.split() if word.lower() not in set(stopwords.words('english'))]
        return clean_mess
    no_punc_tweet = no_user_alpha(new_tweet)
    
    def normalization(tweet_list):
        lem = WordNetLemmatizer()
        normalized_tweet = []
        for word in tweet_list:
            normalized_text = lem.lemmatize(word)
            normalized_tweet.append(normalized_text)
        return normalized_tweet
    return normalization(no_punc_tweet)

var=text_processing(pytesseract.image_to_string(img))

nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')

set(var)

pip install googletrans

from googletrans import Translator
translator = Translator()

b=translator.translate('thank you',dest='hi')

translations = translator.translate(['The quick brown fox', 'jumps over', 'the lazy dog'], dest='ko')
for translation in translations:
  print(translation.origin, ' -> ', translation.text)

pip install googletrans==3.1.0a0

from googletrans import Translator
translator = Translator(service_urls=['translate.googleapis.com'])
translate_text = translator.translate('thank you',dest='hi')  
print(translate_text)

pip install google_trans_new

from google_trans_new import google_translator  
  
translator = google_translator()  
for i in var:
  translate_text = translator.translate(i,lang_tgt='hi')  
  print(translate_text)

